{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81134ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xlrd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import boto3\n",
    "import botocore\n",
    "import requests\n",
    "import os\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a4abda",
   "metadata": {},
   "source": [
    "## CLEANING AND UPLOADING FILES TO NEW BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88fe1098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Downloading 2020 file...\n",
      "Step 2: Creating DataFrame for 2020 file...\n",
      "Step 3: Renaming columns for 2020 file...\n",
      "Step 4: Exporting cleaned data for 2020...\n",
      "Step 5: Uploading cleaned data to https://inep-cleaned.s3.amazonaws.com/...\n",
      "Cleaning and uploading for 2020 is complete!\n",
      "\n",
      "Step 1: Downloading 2021 file...\n",
      "Step 2: Creating DataFrame for 2021 file...\n",
      "Step 3: Renaming columns for 2021 file...\n",
      "Step 4: Exporting cleaned data for 2021...\n",
      "Step 5: Uploading cleaned data to https://inep-cleaned.s3.amazonaws.com/...\n",
      "Cleaning and uploading for 2021 is complete!\n",
      "\n",
      "Step 1: Downloading 2022 file...\n",
      "Step 2: Creating DataFrame for 2022 file...\n",
      "Step 3: Renaming columns for 2022 file...\n",
      "Step 4: Exporting cleaned data for 2022...\n",
      "Step 5: Uploading cleaned data to https://inep-cleaned.s3.amazonaws.com/...\n",
      "Cleaning and uploading for 2022 is complete!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the S3 bucket URLs\n",
    "source_bucket_url = 'https://inep.s3.amazonaws.com/'\n",
    "destination_bucket_url = 'https://inep-cleaned.s3.amazonaws.com/'\n",
    "\n",
    "# List of years for your files\n",
    "years = ['2020', '2021', '2022']\n",
    "\n",
    "for year in years:\n",
    "    # Step 1: Download the file\n",
    "    print(f\"Step 1: Downloading {year} file...\")\n",
    "    source_key = f'MICRODADOS_ENEM_{year}.csv'\n",
    "    destination_key = f'summary_{source_key}'\n",
    "    \n",
    "    source_object_url = source_bucket_url + source_key\n",
    "    response = requests.get(source_object_url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        with open(source_key, 'wb') as local_file:\n",
    "            local_file.write(response.content)\n",
    "    else:\n",
    "        print(f\"Failed to download {year} file. Status code: {response.status_code}\")\n",
    "    \n",
    "        \"\"\"# Print the response content for more details if available\n",
    "        if response.content:\n",
    "            print(\"Response Content:\")\n",
    "            print(response.content.decode('utf-8'))\n",
    "\n",
    "        # Print headers for additional information if available\n",
    "        if response.headers:\n",
    "            print(\"Response Headers:\")\n",
    "            for header, value in response.headers.items():\n",
    "                print(f\"{header}: {value}\")\"\"\"\n",
    "\n",
    "    # Step 2: Create a DataFrame and select specific columns\n",
    "    print(f\"Step 2: Creating DataFrame for {year} file...\")\n",
    "    columns_to_keep = [\n",
    "        'NU_INSCRICAO', 'NU_ANO', 'TP_FAIXA_ETARIA', 'TP_SEXO', 'TP_ESTADO_CIVIL', 'TP_COR_RACA',\n",
    "        'TP_NACIONALIDADE', 'TP_ST_CONCLUSAO', 'TP_ANO_CONCLUIU', 'TP_ESCOLA', 'TP_ENSINO',\n",
    "        'IN_TREINEIRO', 'CO_MUNICIPIO_PROVA', 'NO_MUNICIPIO_PROVA', 'CO_UF_PROVA', 'SG_UF_PROVA',\n",
    "        'NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT', 'NU_NOTA_REDACAO'\n",
    "    ]\n",
    "    \n",
    "    df_MICRODADOS_ENEM_{year} = pd.read_csv(source_key, sep=';', encoding='latin1', usecols=columns_to_keep)\n",
    "    \n",
    "    # Step 3: Rename columns\n",
    "    print(f\"Step 3: Renaming columns for {year} file...\")\n",
    "    df_MICRODADOS_ENEM_{year}.rename(columns={\n",
    "        'NU_INSCRICAO': 'id', 'NU_ANO': 'year', 'TP_FAIXA_ETARIA': 'age_code', 'TP_SEXO': 'sex_code',\n",
    "        'TP_ESTADO_CIVIL': 'civil_code', 'TP_COR_RACA': 'etinicity_code', 'TP_NACIONALIDADE': 'nationality_code',\n",
    "        'TP_ST_CONCLUSAO': 'conclusion_code', 'TP_ANO_CONCLUIU': 'concluion_year', 'TP_ESCOLA': 'school_code',\n",
    "        'TP_ENSINO': 'teaching_code', 'IN_TREINEIRO': 'is_training', 'CO_MUNICIPIO_PROVA': 'municipality_code',\n",
    "        'NO_MUNICIPIO_PROVA': 'municipality_name', 'CO_UF_PROVA': 'uf_code', 'SG_UF_PROVA': 'uf_name',\n",
    "        'NU_NOTA_CN': 'cn_score', 'NU_NOTA_CH': 'ch_score', 'NU_NOTA_LC': 'lc_score',\n",
    "        'NU_NOTA_MT': 'mt_score', 'NU_NOTA_REDACAO': 'essay_score'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Step 4: Export the cleaned data to a new CSV\n",
    "    print(f\"Step 4: Exporting cleaned data for {year}...\")\n",
    "    df_MICRODADOS_ENEM_{year}.to_csv(destination_key, index=False)\n",
    "    \n",
    "    # Step 5: Upload the CSV to the destination bucket\n",
    "    print(f\"Step 5: Uploading cleaned data to {destination_bucket_url}...\")\n",
    "    destination_object_url = destination_bucket_url + destination_key\n",
    "    with open(destination_key, 'rb') as local_file:\n",
    "        response = requests.put(destination_object_url, data=local_file)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        print(f\"Cleaning and uploading for {year} is complete!\\n\")\n",
    "    else:\n",
    "        print(f\"Failed to upload {year} file. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c288d43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Cleanup: Delete the downloaded files\n",
    "os.remove(source_key)\n",
    "os.remove(destination_key)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb3c0ff",
   "metadata": {},
   "source": [
    "## UPLOADING DATA TO POSTGRES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d2418f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>age_code</th>\n",
       "      <th>sex_code</th>\n",
       "      <th>civil_code</th>\n",
       "      <th>etinicity_code</th>\n",
       "      <th>nationality_code</th>\n",
       "      <th>conclusion_code</th>\n",
       "      <th>concluion_year</th>\n",
       "      <th>school_code</th>\n",
       "      <th>...</th>\n",
       "      <th>is_training</th>\n",
       "      <th>municipality_code</th>\n",
       "      <th>municipality_name</th>\n",
       "      <th>uf_code</th>\n",
       "      <th>uf_name</th>\n",
       "      <th>cn_score</th>\n",
       "      <th>ch_score</th>\n",
       "      <th>lc_score</th>\n",
       "      <th>mt_score</th>\n",
       "      <th>essay_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200006271946</td>\n",
       "      <td>2020</td>\n",
       "      <td>11</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1501402</td>\n",
       "      <td>Belém</td>\n",
       "      <td>15</td>\n",
       "      <td>PA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200001195856</td>\n",
       "      <td>2020</td>\n",
       "      <td>11</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2408102</td>\n",
       "      <td>Natal</td>\n",
       "      <td>24</td>\n",
       "      <td>RN</td>\n",
       "      <td>604.1</td>\n",
       "      <td>661.7</td>\n",
       "      <td>595.3</td>\n",
       "      <td>711.3</td>\n",
       "      <td>580.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200001943954</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2927408</td>\n",
       "      <td>Salvador</td>\n",
       "      <td>29</td>\n",
       "      <td>BA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200001908998</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3547304</td>\n",
       "      <td>Santana de Parnaíba</td>\n",
       "      <td>35</td>\n",
       "      <td>SP</td>\n",
       "      <td>620.8</td>\n",
       "      <td>675.0</td>\n",
       "      <td>624.2</td>\n",
       "      <td>759.4</td>\n",
       "      <td>760.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200001634757</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3121605</td>\n",
       "      <td>Diamantina</td>\n",
       "      <td>31</td>\n",
       "      <td>MG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200003132410</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4305207</td>\n",
       "      <td>Cerro Largo</td>\n",
       "      <td>43</td>\n",
       "      <td>RS</td>\n",
       "      <td>498.1</td>\n",
       "      <td>604.7</td>\n",
       "      <td>505.4</td>\n",
       "      <td>526.7</td>\n",
       "      <td>700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>200001379770</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2611606</td>\n",
       "      <td>Recife</td>\n",
       "      <td>26</td>\n",
       "      <td>PE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200001334237</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3550308</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>35</td>\n",
       "      <td>SP</td>\n",
       "      <td>604.6</td>\n",
       "      <td>604.8</td>\n",
       "      <td>562.1</td>\n",
       "      <td>753.2</td>\n",
       "      <td>600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>200006762554</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2507507</td>\n",
       "      <td>João Pessoa</td>\n",
       "      <td>25</td>\n",
       "      <td>PB</td>\n",
       "      <td>439.7</td>\n",
       "      <td>383.5</td>\n",
       "      <td>486.2</td>\n",
       "      <td>448.5</td>\n",
       "      <td>600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>200005146210</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2304400</td>\n",
       "      <td>Fortaleza</td>\n",
       "      <td>23</td>\n",
       "      <td>CE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  year  age_code sex_code  civil_code  etinicity_code  \\\n",
       "0  200006271946  2020        11        F           1               2   \n",
       "1  200001195856  2020        11        M           2               3   \n",
       "2  200001943954  2020         4        F           2               3   \n",
       "3  200001908998  2020         2        M           1               3   \n",
       "4  200001634757  2020         4        F           1               3   \n",
       "5  200003132410  2020         3        F           1               3   \n",
       "6  200001379770  2020         9        M           1               3   \n",
       "7  200001334237  2020         4        M           1               1   \n",
       "8  200006762554  2020         5        F           2               3   \n",
       "9  200005146210  2020         2        M           1               2   \n",
       "\n",
       "   nationality_code  conclusion_code  concluion_year  school_code  ...  \\\n",
       "0                 1                1              11            1  ...   \n",
       "1                 1                1              11            1  ...   \n",
       "2                 2                2               0            2  ...   \n",
       "3                 1                2               0            2  ...   \n",
       "4                 2                1               1            1  ...   \n",
       "5                 1                1               1            1  ...   \n",
       "6                 1                1               6            1  ...   \n",
       "7                 1                1               1            1  ...   \n",
       "8                 1                1               3            1  ...   \n",
       "9                 1                2               0            2  ...   \n",
       "\n",
       "   is_training  municipality_code    municipality_name uf_code  uf_name  \\\n",
       "0            0            1501402                Belém      15       PA   \n",
       "1            0            2408102                Natal      24       RN   \n",
       "2            0            2927408             Salvador      29       BA   \n",
       "3            0            3547304  Santana de Parnaíba      35       SP   \n",
       "4            0            3121605           Diamantina      31       MG   \n",
       "5            0            4305207          Cerro Largo      43       RS   \n",
       "6            0            2611606               Recife      26       PE   \n",
       "7            0            3550308            São Paulo      35       SP   \n",
       "8            0            2507507          João Pessoa      25       PB   \n",
       "9            0            2304400            Fortaleza      23       CE   \n",
       "\n",
       "  cn_score  ch_score  lc_score  mt_score  essay_score  \n",
       "0      NaN       NaN       NaN       NaN          NaN  \n",
       "1    604.1     661.7     595.3     711.3        580.0  \n",
       "2      NaN       NaN       NaN       NaN          NaN  \n",
       "3    620.8     675.0     624.2     759.4        760.0  \n",
       "4      NaN       NaN       NaN       NaN          NaN  \n",
       "5    498.1     604.7     505.4     526.7        700.0  \n",
       "6      NaN       NaN       NaN       NaN          NaN  \n",
       "7    604.6     604.8     562.1     753.2        600.0  \n",
       "8    439.7     383.5     486.2     448.5        600.0  \n",
       "9      NaN       NaN       NaN       NaN          NaN  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the S3 bucket name and file names\n",
    "bucket_name = 'inep-cleaned'\n",
    "file_names = [\n",
    "    'summary_MICRODADOS_ENEM_2020.csv',\n",
    "    'summary_MICRODADOS_ENEM_2021.csv',\n",
    "    'summary_MICRODADOS_ENEM_2022.csv'\n",
    "]\n",
    "\n",
    "# Initialize an empty list to store individual DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Iterate through the specified file names and download each one\n",
    "for file_name in file_names:\n",
    "    # Construct the public S3 URL\n",
    "    s3_url = f'https://{bucket_name}.s3.amazonaws.com/{file_name}'\n",
    "    \n",
    "    # Download the CSV file using requests\n",
    "    response = requests.get(s3_url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        # Read the CSV data into a pandas DataFrame\n",
    "        df = pd.read_csv(StringIO(response.text))\n",
    "        dataframes.append(df)\n",
    "    else:\n",
    "        print(f\"Failed to download {file_name}\")\n",
    "\n",
    "# Combine all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "combined_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53caee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a connection to your PostgreSQL RDS instance\n",
    "host = 'database-2.ckuaogoaistw.us-east-1.rds.amazonaws.com'\n",
    "port = 5432\n",
    "database = 'postgres'\n",
    "user = 'postgres'\n",
    "password = 'postgres'\n",
    "\n",
    "connection = psycopg2.connect(\n",
    "    host=host,\n",
    "    port=port,\n",
    "    database=database,\n",
    "    user=user,\n",
    "    password=password\n",
    ")\n",
    "\n",
    "# create a cursor object\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# create table\n",
    "table_name = 'inep_data' \n",
    "\n",
    "# Set up a SQLAlchemy engine\n",
    "engine = create_engine(f'postgresql://{user}:{password}@{host}:{port}/{database}')\n",
    "\n",
    "# Use Pandas to create the table and insert data\n",
    "combined_df.to_sql(\n",
    "    table_name,\n",
    "    engine,\n",
    "    if_exists='replace',  # You can use 'replace', 'append', or 'fail' depending on your needs\n",
    "    index=False  # Set to False if you don't want to include the DataFrame index as a column\n",
    ")\n",
    "\n",
    "# Commit changes and close the cursor and connection\n",
    "connection.commit()\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d339cf35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
