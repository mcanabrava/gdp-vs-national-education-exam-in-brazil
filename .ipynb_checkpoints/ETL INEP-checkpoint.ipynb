{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fb3bf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xlrd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import boto3\n",
    "import botocore\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfb7260",
   "metadata": {},
   "source": [
    "## CLEANING AND UPLOADING FILES TO NEW BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdc990f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Downloading 2020 file...\n",
      "Step 2: Creating DataFrame for 2020 file...\n",
      "Step 3: Renaming columns for 2020 file...\n",
      "Step 4: Exporting cleaned data for 2020...\n",
      "Step 5: Uploading cleaned data to https://inep-cleaned.s3.amazonaws.com/...\n",
      "Cleaning and uploading for 2020 is complete!\n",
      "\n",
      "Step 1: Downloading 2021 file...\n",
      "Step 2: Creating DataFrame for 2021 file...\n",
      "Step 3: Renaming columns for 2021 file...\n",
      "Step 4: Exporting cleaned data for 2021...\n",
      "Step 5: Uploading cleaned data to https://inep-cleaned.s3.amazonaws.com/...\n",
      "Cleaning and uploading for 2021 is complete!\n",
      "\n",
      "Step 1: Downloading 2022 file...\n",
      "Step 2: Creating DataFrame for 2022 file...\n",
      "Step 3: Renaming columns for 2022 file...\n",
      "Step 4: Exporting cleaned data for 2022...\n",
      "Step 5: Uploading cleaned data to https://inep-cleaned.s3.amazonaws.com/...\n",
      "Cleaning and uploading for 2022 is complete!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the S3 bucket URLs\n",
    "source_bucket_url = 'https://inep.s3.amazonaws.com/'\n",
    "destination_bucket_url = 'https://inep-cleaned.s3.amazonaws.com/'\n",
    "\n",
    "# List of years for your files\n",
    "years = ['2020', '2021', '2022']\n",
    "\n",
    "for year in years:\n",
    "    # Step 1: Download the file\n",
    "    print(f\"Step 1: Downloading {year} file...\")\n",
    "    source_key = f'MICRODADOS_ENEM_{year}.csv'\n",
    "    destination_key = f'summary_{source_key}'\n",
    "    \n",
    "    source_object_url = source_bucket_url + source_key\n",
    "    response = requests.get(source_object_url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        with open(source_key, 'wb') as local_file:\n",
    "            local_file.write(response.content)\n",
    "    else:\n",
    "        print(f\"Failed to download {year} file. Status code: {response.status_code}\")\n",
    "    \n",
    "        \"\"\"# Print the response content for more details if available\n",
    "        if response.content:\n",
    "            print(\"Response Content:\")\n",
    "            print(response.content.decode('utf-8'))\n",
    "\n",
    "        # Print headers for additional information if available\n",
    "        if response.headers:\n",
    "            print(\"Response Headers:\")\n",
    "            for header, value in response.headers.items():\n",
    "                print(f\"{header}: {value}\")\"\"\"\n",
    "\n",
    "    # Step 2: Create a DataFrame and select specific columns\n",
    "    print(f\"Step 2: Creating DataFrame for {year} file...\")\n",
    "    columns_to_keep = [\n",
    "        'NU_INSCRICAO', 'NU_ANO', 'TP_FAIXA_ETARIA', 'TP_SEXO', 'TP_ESTADO_CIVIL', 'TP_COR_RACA',\n",
    "        'TP_NACIONALIDADE', 'TP_ST_CONCLUSAO', 'TP_ANO_CONCLUIU', 'TP_ESCOLA', 'TP_ENSINO',\n",
    "        'IN_TREINEIRO', 'CO_MUNICIPIO_PROVA', 'NO_MUNICIPIO_PROVA', 'CO_UF_PROVA', 'SG_UF_PROVA',\n",
    "        'NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT', 'NU_NOTA_REDACAO'\n",
    "    ]\n",
    "    \n",
    "    df = pd.read_csv(source_key, sep=';', encoding='latin1', usecols=columns_to_keep)\n",
    "    \n",
    "    # Step 3: Rename columns\n",
    "    print(f\"Step 3: Renaming columns for {year} file...\")\n",
    "    df.rename(columns={\n",
    "        'NU_INSCRICAO': 'id', 'NU_ANO': 'year', 'TP_FAIXA_ETARIA': 'age_code', 'TP_SEXO': 'sex_code',\n",
    "        'TP_ESTADO_CIVIL': 'civil_code', 'TP_COR_RACA': 'etinicity_code', 'TP_NACIONALIDADE': 'nationality_code',\n",
    "        'TP_ST_CONCLUSAO': 'conclusion_code', 'TP_ANO_CONCLUIU': 'concluion_year', 'TP_ESCOLA': 'school_code',\n",
    "        'TP_ENSINO': 'teaching_code', 'IN_TREINEIRO': 'is_training', 'CO_MUNICIPIO_PROVA': 'municipality_code',\n",
    "        'NO_MUNICIPIO_PROVA': 'municipality_name', 'CO_UF_PROVA': 'uf_code', 'SG_UF_PROVA': 'uf_name',\n",
    "        'NU_NOTA_CN': 'cn_score', 'NU_NOTA_CH': 'ch_score', 'NU_NOTA_LC': 'lc_score',\n",
    "        'NU_NOTA_MT': 'mt_score', 'NU_NOTA_REDACAO': 'essay_score'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Step 4: Export the cleaned data to a new CSV\n",
    "    print(f\"Step 4: Exporting cleaned data for {year}...\")\n",
    "    df.to_csv(destination_key, index=False)\n",
    "    \n",
    "    # Step 5: Upload the CSV to the destination bucket\n",
    "    print(f\"Step 5: Uploading cleaned data to {destination_bucket_url}...\")\n",
    "    destination_object_url = destination_bucket_url + destination_key\n",
    "    with open(destination_key, 'rb') as local_file:\n",
    "        response = requests.put(destination_object_url, data=local_file)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        print(f\"Cleaning and uploading for {year} is complete!\\n\")\n",
    "    else:\n",
    "        print(f\"Failed to upload {year} file. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "447fe324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup: Delete the downloaded files\n",
    "os.remove(source_key)\n",
    "os.remove(destination_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaabfd2",
   "metadata": {},
   "source": [
    "## UPLOADING DATA TO POSTGRES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103b5637",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
